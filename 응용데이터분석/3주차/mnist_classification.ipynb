{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import time \n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eeac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_img(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, img_size)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c696d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_label(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87db445",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "dataset_dir = \"mnist\"\n",
    "save_file = dataset_dir + \"/mnist.pkl\"\n",
    "\n",
    "train_num = 60000\n",
    "test_num = 10000\n",
    "img_dim = (1, 28, 28)\n",
    "img_size = 784\n",
    "\n",
    "dataset = {}\n",
    "dataset['train_img'] =  _load_img(key_file['train_img'])\n",
    "dataset['train_label'] = _load_label(key_file['train_label'])    \n",
    "dataset['test_img'] = _load_img(key_file['test_img'])\n",
    "dataset['test_label'] = _load_label(key_file['test_label'])\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(dataset, f, -1)\n",
    "\n",
    "for key in ('train_img', 'test_img'):\n",
    "    dataset[key] = dataset[key].astype(np.float32)\n",
    "    dataset[key] /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset['train_img'][2000].reshape(28, 28), cmap = cm.binary) #binary형태의 이미지 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = map(\n",
    "    torch.tensor, (dataset['train_img'], dataset['train_label'], dataset['test_img'], dataset['test_label'])\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 20\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_test, y_test)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224263b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6526de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126210dd-511a-4b87-a3a2-2cf8344d84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baacdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb.to(dev)), yb.to(dev))\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_model = Mnist_CNN()\n",
    "gpu_model.to(dev)\n",
    "opt = optim.SGD(gpu_model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "gpu_start = time.time() \n",
    "\n",
    "fit(30, gpu_model, loss_func, opt, train_dl, valid_dl)\n",
    "\n",
    "gpu_training_time = time.time() - gpu_start\n",
    "print(\"gpu training time : \", round(gpu_training_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66555624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "predict_dev = torch.device(\"cpu\")\n",
    "gpu_model.to(predict_dev)\n",
    "\n",
    "y_pred = gpu_model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = []\n",
    "label = dataset['test_label']\n",
    "for r in range(0,10000):\n",
    "    predict_result.append(np.argmax(y_pred.detach().numpy()[r]))\n",
    "\n",
    "f1_result = f1_score(label, predict_result, average = None)\n",
    "print(f1_result)\n",
    "print(np.mean(f1_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a56a8-52ff-4b5b-ae23-05767158ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(label, predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b3859-215f-4f9c-8634-3d3502f6d1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
